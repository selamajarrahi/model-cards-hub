# Best Model For X: Decision Trees

> Quick decision guides for choosing the right model for your task.

---

## ğŸ§  Complex Reasoning

```
Do you need PhD-level accuracy?
â”‚
â”œâ”€â”€ YES: GPT-5.2 (100% AIME, best GPQA)
â”‚
â””â”€â”€ NO
    â”‚
    Is cost a major concern?
    â”‚
    â”œâ”€â”€ YES: DeepSeek R1 (open, strong reasoning)
    â”‚
    â””â”€â”€ NO
        â”‚
        Do you need very long context (>200K)?
        â”‚
        â”œâ”€â”€ YES: Gemini 3 Pro (1M context)
        â”‚
        â””â”€â”€ NO: Claude Opus 4 (great balance)
```

**Winner by scenario:**
| Scenario | Best Model |
|----------|------------|
| Math competition problems | GPT-5.2 |
| Legal document analysis | Claude Opus 4 |
| Scientific reasoning | GPT-5.2 |
| Budget reasoning tasks | DeepSeek R1 |

---

## ğŸ’» Coding & Software Development

```
What type of coding task?
â”‚
â”œâ”€â”€ Full codebase understanding/refactoring
â”‚   â”‚
â”‚   â”œâ”€â”€ Need to self-host? â†’ Llama 4 + Augment Code
â”‚   â””â”€â”€ API is fine â†’ Claude Opus 4 (best SWE-bench)
â”‚
â”œâ”€â”€ Quick completions/autocomplete
â”‚   â”‚
â”‚   â”œâ”€â”€ Free tier â†’ Codeium, Continue
â”‚   â””â”€â”€ Paid â†’ GitHub Copilot, Cursor
â”‚
â”œâ”€â”€ Code review
â”‚   â””â”€â”€ Claude Opus 4 or GPT-5.2
â”‚
â””â”€â”€ Learning/explanation
    â””â”€â”€ Any top model works; Claude is known for clear explanations
```

**Winner by scenario:**
| Scenario | Best Model |
|----------|------------|
| SWE-bench tasks | Claude Opus 4 (80.9%) |
| Competition programming | GPT-5.2 |
| Open-source contribution | DeepSeek R1 + Llama 4 |
| IDE integration | Cursor (Claude/GPT) |
| Code explanation | Claude (any tier) |

---

## ğŸ¨ Image Generation

```
What's your priority?
â”‚
â”œâ”€â”€ Photorealism
â”‚   â”‚
â”‚   â”œâ”€â”€ Free â†’ SDXL, Stable Diffusion 3
â”‚   â””â”€â”€ Paid â†’ Midjourney v6, FLUX 1.1 Pro
â”‚
â”œâ”€â”€ Text rendering
â”‚   â””â”€â”€ FLUX 1.1 Pro (best text accuracy)
â”‚
â”œâ”€â”€ Speed
â”‚   â””â”€â”€ FLUX Schnell, SDXL Turbo
â”‚
â”œâ”€â”€ Artistic/stylized
â”‚   â””â”€â”€ Midjourney v6
â”‚
â””â”€â”€ Enterprise/compliance
    â””â”€â”€ DALL-E 3 (OpenAI's content policy)
```

**Winner by scenario:**
| Scenario | Best Model |
|----------|------------|
| Marketing images | Midjourney v6 |
| Product mockups | FLUX 1.1 Pro |
| Text-heavy graphics | FLUX 1.1 Pro |
| Rapid prototyping | FLUX Schnell |
| Self-hosted | Stable Diffusion 3 |

---

## ğŸ¬ Video Generation

```
What type of video?
â”‚
â”œâ”€â”€ Cinematic/high quality
â”‚   â””â”€â”€ Seedance 2.0 (2K, native audio)
â”‚
â”œâ”€â”€ Quick clips
â”‚   â”‚
â”‚   â”œâ”€â”€ API available â†’ Runway Gen-3
â”‚   â””â”€â”€ Self-hosted â†’ Open-Sora
â”‚
â”œâ”€â”€ Lip sync/talking heads
â”‚   â””â”€â”€ HeyGen, Synthesia
â”‚
â””â”€â”€ Animation/motion
    â””â”€â”€ Pika, Runway
```

**Winner by scenario:**
| Scenario | Best Model |
|----------|------------|
| Film production | Seedance 2.0 |
| Marketing videos | Runway Gen-3 |
| Training videos | HeyGen |
| Experimental | Sora 2 (when available) |

---

## ğŸŒ Multilingual Tasks

```
How many languages?
â”‚
â”œâ”€â”€ Chinese + English
â”‚   â””â”€â”€ Qwen 3, DeepSeek, Doubao
â”‚
â”œâ”€â”€ European languages
â”‚   â””â”€â”€ Mistral Large, Gemini 3 Pro
â”‚
â”œâ”€â”€ 50+ languages
â”‚   â””â”€â”€ Gemini 3 Pro (best multilingual)
â”‚
â””â”€â”€ Low-resource languages
    â””â”€â”€ GPT-5.2 or Gemini 3 Pro
```

**Winner by scenario:**
| Scenario | Best Model |
|----------|------------|
| Chinese NLP | Qwen 3, Doubao |
| European content | Mistral Large |
| Global deployment | Gemini 3 Pro |
| Translation | Google Translate API + Gemini |

---

## ğŸ’¼ Enterprise Deployment

```
What's your primary constraint?
â”‚
â”œâ”€â”€ Data privacy/on-prem required
â”‚   â”‚
â”‚   â”œâ”€â”€ Maximum capability â†’ Llama 4 400B
â”‚   â”œâ”€â”€ Balanced â†’ Llama 4 70B
â”‚   â””â”€â”€ Edge deployment â†’ Llama 4 8B
â”‚
â”œâ”€â”€ Compliance/audit trail
â”‚   â”‚
â”‚   â”œâ”€â”€ SOC 2 needed â†’ Claude (Anthropic), GPT (OpenAI)
â”‚   â””â”€â”€ HIPAA â†’ Azure OpenAI, AWS Bedrock
â”‚
â”œâ”€â”€ Cost optimization
â”‚   â”‚
â”‚   â”œâ”€â”€ High volume â†’ Self-host Llama 4, DeepSeek
â”‚   â””â”€â”€ Variable volume â†’ Pay-per-token APIs
â”‚
â””â”€â”€ SLA/reliability
    â””â”€â”€ Azure OpenAI, AWS Bedrock, GCP Vertex
```

**Winner by scenario:**
| Scenario | Best Solution |
|----------|---------------|
| Air-gapped environment | Llama 4 (on-prem) |
| Financial services | Azure OpenAI (compliance) |
| Healthcare | AWS Bedrock (HIPAA) |
| Startup/scale-up | Direct API (Claude/OpenAI) |
| High-volume inference | Self-hosted vLLM |

---

## ğŸ“š Research & Analysis

```
What type of research?
â”‚
â”œâ”€â”€ Literature review
â”‚   â”‚
â”‚   â”œâ”€â”€ Many papers â†’ Gemini 3 Pro (1M context)
â”‚   â””â”€â”€ Deep analysis â†’ Claude Opus 4
â”‚
â”œâ”€â”€ Data analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ Code generation â†’ Claude Opus 4
â”‚   â””â”€â”€ Statistical reasoning â†’ GPT-5.2
â”‚
â”œâ”€â”€ Scientific writing
â”‚   â””â”€â”€ Claude Opus 4 (clear writing)
â”‚
â””â”€â”€ Fact verification
    â””â”€â”€ GPT-5.2 (best SimpleQA)
```

---

## âš¡ Speed vs. Quality Trade-offs

| Priority | Best Choice |
|----------|-------------|
| Maximum quality | GPT-5.2, Claude Opus 4 |
| Balance (recommended) | Claude Sonnet 4, GPT-4o |
| Maximum speed | Claude Haiku 3, GPT-5.2-mini |
| Self-hosted speed | vLLM + Llama 4 |

---

## ğŸ’¡ Quick Reference Table

| Task | Best Model | Runner-up |
|------|------------|-----------|
| Complex math | GPT-5.2 | DeepSeek R1 |
| Coding (SWE) | Claude Opus 4 | GPT-5.2 |
| Long context | Gemini 3 Pro | GPT-5.2 |
| Image gen | FLUX 1.1 Pro | Midjourney v6 |
| Video gen | Seedance 2.0 | Runway Gen-3 |
| Multilingual | Gemini 3 Pro | Qwen 3 |
| Budget | DeepSeek R1 | Qwen 3 |
| Self-host | Llama 4 | DeepSeek R1 |
| Privacy | Llama 4 (local) | Claude (Anthropic) |

---

*Updated: February 2026*
