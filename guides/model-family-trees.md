# ğŸŒ³ AI Model Family Trees

> Understanding the lineages and evolution of major AI models

---

## OpenAI / GPT Family

```
GPT-1 (2018)
    â”‚ 117M parameters
    â”‚ Introduced transformer decoder for generation
    â”‚
    â””â”€â–º GPT-2 (2019)
        â”‚ 1.5B parameters
        â”‚ "Too dangerous to release" (later released)
        â”‚
        â””â”€â–º GPT-3 (2020)
            â”‚ 175B parameters
            â”‚ Few-shot learning breakthrough
            â”‚
            â”œâ”€â–º GPT-3.5 (2022)
            â”‚   â”‚ ChatGPT's original model
            â”‚   â”‚ RLHF introduction
            â”‚   â”‚
            â”‚   â””â”€â–º GPT-3.5-Turbo
            â”‚       Faster, cheaper API
            â”‚
            â””â”€â–º GPT-4 (2023)
                â”‚ Multimodal (vision)
                â”‚ Significant reasoning improvement
                â”‚
                â”œâ”€â–º GPT-4-Turbo (2023)
                â”‚   â”‚ 128K context, cheaper
                â”‚   â”‚
                â”‚   â””â”€â–º GPT-4o (2024)
                â”‚       â”‚ Omni model, native multimodal
                â”‚       â”‚ Audio, image, video understanding
                â”‚       â”‚
                â”‚       â””â”€â–º GPT-4o-mini
                â”‚           Smaller, faster, cheaper
                â”‚
                â””â”€â–º o1 / o3 (2024-2025)
                    â”‚ Reasoning models
                    â”‚ "Thinking" tokens
                    â”‚
                    â””â”€â–º GPT-5 / GPT-5.2 (2025-2026)
                        Next generation flagship
```

---

## Anthropic / Claude Family

```
Constitutional AI Research (2022)
    â”‚ RLHF + Constitutional approach
    â”‚
    â””â”€â–º Claude 1.0 (2023)
        â”‚ First public model
        â”‚
        â””â”€â–º Claude 1.3 / Claude Instant
            â”‚ Improved speed and quality
            â”‚
            â””â”€â–º Claude 2.0 (2023)
                â”‚ 100K context
                â”‚
                â””â”€â–º Claude 2.1
                    â”‚ 200K context
                    â”‚
                    â””â”€â–º Claude 3 Family (2024)
                        â”‚
                        â”œâ”€â–º Claude 3 Haiku
                        â”‚   Fast, cheap, good
                        â”‚
                        â”œâ”€â–º Claude 3 Sonnet
                        â”‚   Best value
                        â”‚
                        â””â”€â–º Claude 3 Opus
                            â”‚ Most capable
                            â”‚
                            â””â”€â–º Claude 3.5 Sonnet (2024)
                                â”‚ Opus-level at Sonnet price
                                â”‚
                                â””â”€â–º Claude 4 Family (2025)
                                    â”‚
                                    â”œâ”€â–º Claude Sonnet 4
                                    â”‚   Production workhorse
                                    â”‚
                                    â””â”€â–º Claude Opus 4
                                        Extended thinking
                                        Best coding/reasoning
```

---

## Meta / Llama Family

```
OPT (2022)
    â”‚ Open Pre-trained Transformer
    â”‚ Research release, various sizes
    â”‚
    â””â”€â–º LLaMA 1 (2023)
        â”‚ "Leaked" then open-sourced
        â”‚ 7B, 13B, 33B, 65B
        â”‚ Spawned entire ecosystem
        â”‚
        â”œâ”€â–º Alpaca (Stanford)
        â”‚   Fine-tuned on instructions
        â”‚
        â”œâ”€â–º Vicuna
        â”‚   ShareGPT conversations
        â”‚
        â”œâ”€â–º Koala, WizardLM, etc.
        â”‚   Various community fine-tunes
        â”‚
        â””â”€â–º Llama 2 (2023)
            â”‚ Official Meta release
            â”‚ 7B, 13B, 70B + Chat variants
            â”‚ Commercial license
            â”‚
            â”œâ”€â–º Code Llama
            â”‚   Code-specialized
            â”‚
            â””â”€â–º Llama 3 (2024)
                â”‚ 8B, 70B (later 405B)
                â”‚ Much improved quality
                â”‚
                â”œâ”€â–º Llama 3.1
                â”‚   128K context
                â”‚
                â”œâ”€â–º Llama 3.2
                â”‚   â”‚ Multimodal (vision)
                â”‚   â”‚ Smaller sizes (1B, 3B)
                â”‚   â”‚
                â”‚   â””â”€â–º Llama 3.3
                â”‚       70B quality at lower cost
                â”‚
                â””â”€â–º Llama 4 (Expected 2026)
                    MoE architecture?
```

---

## Chinese AI Labs

### Alibaba / Qwen

```
Qwen (2023)
    â”‚ First release, 7B-72B
    â”‚
    â””â”€â–º Qwen 1.5 (2024)
        â”‚ Improved multilingual
        â”‚
        â””â”€â–º Qwen 2 (2024)
            â”‚ Better reasoning
            â”‚ Code & Math focus
            â”‚
            â””â”€â–º Qwen 2.5 (2024)
                â”‚ Up to 72B
                â”‚ Strong benchmarks
                â”‚
                â””â”€â–º Qwen 3 (2025)
                    Up to 235B
                    Apache 2.0
                    Near-GPT-4 quality
```

### DeepSeek

```
DeepSeek LLM (2023)
    â”‚ Initial 7B-67B models
    â”‚
    â””â”€â–º DeepSeek-Coder (2024)
        â”‚ Code-specialized
        â”‚
        â””â”€â–º DeepSeek V2 (2024)
            â”‚ MoE architecture
            â”‚ Very cost-efficient
            â”‚
            â””â”€â–º DeepSeek V3 (2024)
                â”‚ 671B MoE
                â”‚ $0.27/M tokens
                â”‚
                â””â”€â–º DeepSeek R1 (2025)
                    â”‚ Reasoning model
                    â”‚ Matches o1
                    â”‚ MIT license
                    â”‚
                    â””â”€â–º DeepSeek R1 Distilled
                        Various sizes (7B-70B)
```

### Moonshot / Kimi

```
Kimi (2024)
    â”‚ 128K context pioneer
    â”‚
    â””â”€â–º Kimi K1 (2024)
        â”‚ Improved reasoning
        â”‚
        â””â”€â–º Kimi K2 (2025)
            1T parameters (32B active)
            MoE architecture
            Muon optimizer
            Agentic focus
```

---

## Google / DeepMind

```
BERT (2018) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Encoder-only, revolutionized NLU              â”‚
    â”‚                                                â”‚
T5 (2020) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
    â”‚ Encoder-decoder                    â”‚          â”‚
    â”‚                                    â”‚          â”‚
PaLM (2022) â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ 540B parameters
    â”‚
    â””â”€â–º PaLM 2 (2023)
        â”‚ Powering Bard (then Gemini)
        â”‚
        â””â”€â–º Gemini 1.0 (2023)
            â”‚ Nano, Pro, Ultra
            â”‚ Native multimodal
            â”‚
            â”œâ”€â–º Gemini 1.5 Pro (2024)
            â”‚   â”‚ 1M context
            â”‚   â”‚
            â”‚   â””â”€â–º Gemini 1.5 Flash
            â”‚       Fast & cheap
            â”‚
            â””â”€â–º Gemini 2.0 Flash (2024)
                â”‚ Improved speed & quality
                â”‚
                â””â”€â–º Gemini 3 (2025-2026)
                    Pro, Ultra
                    Next generation
```

---

## Image Generation

### Stability AI / Stable Diffusion

```
Stable Diffusion 1.x (2022)
    â”‚ Open source revolution
    â”‚ Latent diffusion
    â”‚
    â””â”€â–º Stable Diffusion 2.x (2022)
        â”‚ Improved quality, controversies
        â”‚
        â””â”€â–º SDXL (2023)
            â”‚ 1024x1024 native
            â”‚
            â”œâ”€â–º SDXL-Turbo
            â”‚   Few-step generation
            â”‚
            â””â”€â–º Stable Diffusion 3 (2024)
                â”‚ MMDiT architecture
                â”‚
                â””â”€â–º SD 3.5 (2024)
                    Improved quality
```

### Black Forest Labs / FLUX

```
(Stable Diffusion creators left)
    â”‚
    â””â”€â–º FLUX.1 (2024)
        â”‚ Pro, Dev, Schnell variants
        â”‚ Best-in-class quality
        â”‚
        â””â”€â–º FLUX 1.1 Pro (2024)
            â”‚ 6x faster
            â”‚ Better quality
            â”‚
            â””â”€â–º FLUX 2.0 (Expected 2026)
                Video support?
```

### OpenAI / DALL-E

```
DALL-E 1 (2021)
    â”‚ First text-to-image transformer
    â”‚
    â””â”€â–º DALL-E 2 (2022)
        â”‚ Diffusion-based
        â”‚ Much improved
        â”‚
        â””â”€â–º DALL-E 3 (2023)
            â”‚ Native ChatGPT integration
            â”‚ Better text rendering
            â”‚
            â””â”€â–º DALL-E 4 (Expected)
```

---

## Video Generation

```
Make-A-Video (Meta, 2022) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Early research                              â”‚
    â”‚                                             â”‚
Imagen Video (Google, 2022) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Research milestone                          â”‚
    â”‚                                             â”‚
Gen-2 (Runway, 2023) â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ First practical tool                        â”‚
    â”‚                                             â”‚
Sora (OpenAI, 2024) â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ Transformer-based
    â”‚ 60s+ videos
    â”‚
â”œâ”€â–º Kling (Kuaishou)
â”‚   Chinese competitor
â”‚
â”œâ”€â–º Veo (Google)
â”‚   Gemini-powered
â”‚
â””â”€â–º Seedance (ByteDance)
    Multi-modal input
    Native audio
```

---

## Key Takeaways

### Trends Across Families

1. **Scaling:** Models get bigger, then efficient (MoE)
2. **Multimodal:** Vision â†’ Audio â†’ Video
3. **Context:** 4K â†’ 128K â†’ 1M+
4. **Reasoning:** RLHF â†’ Chain-of-thought â†’ Thinking tokens
5. **Open Source:** Catching up to closed models

### Who's Winning?

| Category | Current Leader | Rising Challenger |
|----------|---------------|-------------------|
| Flagship LLM | Claude Opus 4 | GPT-5 |
| Value LLM | DeepSeek R1 | Qwen 3 |
| Open Source | DeepSeek R1 | Llama 4 |
| Image | FLUX 1.1 Pro | - |
| Video | Sora 2 | Seedance 2.0 |

---

ğŸ“š **Related:**
- [Model Comparison Matrix](comparison-matrix.md)
- [Models to Watch](models-to-watch.md)
